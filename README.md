# ğŸš€ Microservices DevOps Project: Flask App on AKS

## All screenshots and links provided at the end of this file

This project demonstrates containerizing a Python Flask microservice, deploying it to an Azure Kubernetes Service (AKS) cluster provisioned via Terraform, automating CI/CD with GitHub Actions, and monitoring it using Prometheus and Grafana.
---
## ğŸ“‹ Project Objectives

Â **Dockerize** the Flask app (`run.py`) Â 
Â **Provision** an AKS cluster using Terraform Â 
Â **Deploy** the microservice via Kubernetes manifests Â 
Â **Expose** the service externally using a LoadBalancer Â 
Â **Automate CI/CD** using GitHub Actions Â 
Â **Monitor** the app and cluster via Prometheus & Grafana
---
## ğŸ Application Overview

A simple Flask-based microservice that listens on port **5000**, with an endpoint defined in `run.py`.
---
## ğŸ³ Dockerization

Multi-stage Dockerfile to ensure a clean and minimal image:

```dockerfile
FROM python:3.9-slim AS builder
WORKDIR /app
COPY requirements.txt .
RUN pip install --user --no-cache-dir -r requirements.txt
FROM python:3.9-slim
WORKDIR /app
COPY . .
COPY --from=builder /root/.local /root/.local
ENV PATH=/root/.local/bin:$PATH
EXPOSE 5000
CMD ["python", "run.py"]
---

âœ… Docker image build, tagged and pushed to Docker Hub:
    docker build -t ${{ secrets.DOCKER_USERNAME }}/flask-app:latest .
    docker push ${{ secrets.DOCKER_USERNAME }}/flask-app:latest

Note
    we need to engage sort of dynamic tagging in the build and push process, it is set here as :latest for demo purposes
_______________________________________________________________________________________________________________

â˜ï¸ Kubernetes Cluster Provisioning
Managed via Terraform in the terraform/ directory:

terraform init
terraform plan
terraform apply -auto-approve

This creates an AKS cluster (resource group, AKS-cluster) on Azure.
_______________________________________________________________________________________________________________

ğŸš€ Application Deployment

Kubernetes manifests are in k8s/:
Â  Â  deployment.yaml â€“ 2 replicas, container port 5000
Â  Â  service.yaml â€“ LoadBalancer on port 80 â†’ 5000
Â  Â  namespace.yaml - the monitoring namespace
Deploy with:
Â  Â  kubectl apply -f k8s/
_______________________________________________________________________________________________________________

ğŸŒ External Access

$ kubectl get svc microservice-service
NAME Â  Â  Â  Â  Â  Â  Â  Â  Â  TYPE Â  Â  Â  Â  Â  CLUSTER-IP Â  EXTERNAL-IP Â  PORT(S) Â  Â  Â  Â AGE
microservice-service Â  LoadBalancer Â  10.0.1.165 Â  51.8.15.47 Â  Â 80:31115/TCP Â  130m

âœ… App URL: http://51.8.15.47/
_______________________________________________________________________________________________________________

ğŸ” CI/CD with GitHub Actions

Workflow located at .github/workflows/deploy.yml automates:
Â  Â  - Cloning the repo
Â  Â  - Docker build & dockerhub push (remonadly/flask-app:latest)
Â  Â  - Terraform provisioning (in case deploying infrastructure from scratsh, DR situation for example)
Â  Â  - AKS deployment using azure/k8s-deploy
Â  Â  - Helm install of Prometheus and Grafana (in case deploying infrastructure from scratsh, DR situation for example)

NOTE: 
    All the hashed lines in the workflow code should be enabled and used only when deploying everything from scratsh including the infrastructure and monitoring stack. And should be hashed when updating only the application deployed on AKS.

    A ServicePrincipal was created, assumed a contributor role and its json was placed as a secret in Github actions for the authentication/Integration between GitHub actions and Azure.

    A Docker Access Token should provided for the authentication/Integration between GitHub actions and Docker hub.
_______________________________________________________________________________________________________________

ğŸ“Š Monitoring Stack

    Monitoring stack was deployed in "monitoring" name space
Â  Â  Deployed Prometheus Helm charts internally.
    Modified and deployed Grafana Helm charts to be exposed by a Loadbalancer service for external access.

Note:
    Both charts can be modified as needed from the values.yaml file

Prometheus
Â  Â  Prometheus added as data source in grafana with below URL:
Â  Â  Â  Â  http://prometheus-server.monitoring.svc.cluster.local

Grafana Exposed via LoadBalancer

Â  Â  $ kubectl get svc -n monitoring
Â  Â  NAME Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â TYPE Â  Â  Â  Â  Â  CLUSTER-IP Â  Â  EXTERNAL-IP Â  Â  Â PORT(S) Â  Â  Â  Â AGE 
Â  Â  grafana Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  LoadBalancer Â  10.0.101.237 Â  74.179.225.105 Â  80:31941/TCP Â  139m

âœ… Grafana URL: http://74.179.225.105:80

To get grafana admin password: 
Â  Â  kubectl get secret --namespace monitoring grafana -o jsonpath="{.data.admin-password}" | base64 --decode ; echo

âœ… Grafana Login:
Â  Â  user:admin 
Â  Â  Password: oaIsOKNUYR39Fmvgp8yXhdQbtutNtUJM733MWcAY

Note: 
Â  Â  Two standard dashboards, predefined by Grafana Labs, were imported and used in our Grafana instance to monitor our solution. However, dashboards can be created and customized locally according to business needs and must be deployed in an IAC manner using the K8s CRDs, CRs, and K8s operator.

    Imported dashboards IDs:
    Â  Â  ID: 315 Â  "Kubernetes cluster monitoring (via Prometheus)"
    Â  Â  ID: 1860 Â "Node Exporter Full"
    
           ![Alt text](Screenshots/Dashboards.png) 

    Kubernetes cluster monitoring Dashboard:

            ![Alt text](Screenshots/K8s-cluster-dashboard.png)    

    Node Exporter Full dashboard
            
            ![Alt text](Screenshots/Node-Exporter-Full.png) 

link to get any predefined standard Grafana dashboards : https://grafana.com/grafana/dashboards/
_______________________________________________________________________________________________________________

ğŸ“‚ Project Structure
.
â”œâ”€â”€ .github/workflows/deploy.yml
â”œâ”€â”€ app/
â”‚ Â  â”œâ”€â”€ routes
â”‚ Â  â”œâ”€â”€ services
â”‚ Â  â””â”€â”€ main.py
â”‚ Â  â””â”€â”€ _init_.py
â”œâ”€â”€ k8s/
â”‚ Â  â”œâ”€â”€ deployment.yaml
â”‚ Â  â”œâ”€â”€ service.yaml
â”‚ Â  â””â”€â”€ namespace.yaml
â”œâ”€â”€ terraform/
â”‚ Â  â”œâ”€â”€ main.tf
â”‚ Â  â”œâ”€â”€ variables.tf
â”‚ Â  â””â”€â”€ outputs.tf
â”‚ Â  â””â”€â”€ provider.tf
â”œâ”€â”€ Helm_charts/
â”‚ Â  â”œâ”€â”€ prometheus/
â”‚ Â  â””â”€â”€ grafana/
â”œâ”€â”€ run.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md

_______________________________________________________________________________________________________________

Screenshots & links:

    - The Github repo link: https://github.com/remonadly/flask-app
    - App URL: http://51.8.15.47/users
    - Grafana URL: http://74.179.225.105:80
    - Grafana Login:
    Â  Â  user:admin 
    Â  Â  Password: oaIsOKNUYR39Fmvgp8yXhdQbtutNtUJM733MWcAY
    
![Application](https://raw.githubusercontent.com/remonadly/flask-app/main/Screenshots/application.PNG)

![Alt text](Screenshots/nodes.PNG)
![Alt text](Screenshots/pod.PNG)
![Alt text](Screenshots/pods2.PNG)
![Alt text](Screenshots/svc.PNG)
![Alt text](Screenshots/svc2.PNG)

![alt text](image.png)











